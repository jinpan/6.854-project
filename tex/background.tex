\section{Background}
We formally introduce the problem of maximum concurrent flow. We
start with a directed graph $G(V,E)$ with edge capacities 
$c: e \rightarrow \mathbb{R}^+$,
 and $k$ commodities with source $s_j$ and sink $t_j$ for
commodity $j$. Each commodity also has an associated demand
$d(j)$. The problem of maximum concurrent flow is to find a feasible
flow that maximizes the minimal ratio of flow sent to commodity $j$ to the
demand of commodity $j$, over all commodities. Formally, maximum
concurrent flow finds a flow $f$ that maximizes $\lambda$, where for a given flow $f$ that routes $f_j$
units of commodity $j$ from $s_j$ to $t_j$, 
$$\lambda = \min_{j}(f_j/d(j))$$

We remember that a feasible flow preserves capacity constraints: 
$$\sum_j f_j(u,v) \leq c(u,v)$$
where $f_j(u,v)$ represents the flow of commodity $j$ through edge
$(u,v)$ for each edge $((u,v))\in E$, and maintains flow conservation:
$$\sum_{v\in V} f_j(u,v)=0$$ 
for $v\neq s_j,t_j$, for all commodities $j$ and defining
$f_j(u,v)=-f_j(v,u)$. Intuitively, we can describe the maximum
concurrent flow problem as the following situation: we want to send
commodities to their respective sinks, but instead of shooting for the
bare minimum of demand satisfaction, we want to maximize the ratio of
supply to demand for all commodities. This differs from other
multicommodity flow variants, such as the maximum multi-commodity flow
problem where the goal is to simply maximize total throughput from
sources to sinks with no demands on each commodity. Maximizing the minimum ratio is often more desirable in practice,
as this ensures that all commodities that can be filled will be at least partially filled.

Typically the problem of maximum concurrent flow is formulated under the context of a linear
program. If we let $\mathcal{F}_j$ be the set of flows that send $d(j)$ units
of commodity j from $s_j$ to $t_j$, letting
 $\mathcal{F}=\cup_{j=1}^k \mathcal{F}_j$, the set of flows that route
$d(j)$ units of flow from $s_j$ to $t_j$ for any fixed $j$. We can
formulate a linear program with a variable $x(f)$ for each element
$f\in \mathcal{F}$ as follows:
\begin{align*}
\text{max     } \lambda \\
\text{s.t. }\sum_{f\in \cal{F}}f_e\cdot x(f) \leq c(e) \;\;\forall\;
e\in E \\
\sum_{f\in \cal{F}_j} x(f)\geq \lambda \;\;\;\forall\; 1\leq j\leq k \\
x\geq 0,\; \lambda\geq 0.
\end{align*}
Where $f_e$ is defined as the amount of flow that $f$ sends across edge $e$. In this case, $x(f)$ is defined as the fractional amount of times we use the
primitive flow $f$, sending $d(j)$ units of commodity $j$ from $s_j$
to $t_j$ for some $j$. Decoded, the first constraint maintains that no
edge has flow exceeding its capacity. For a particular $j$, the second
constraint ensures that we send more than $\lambda d(j)$ flow to
$t_j$. 

Alternatively, we can model this problem with a
different LP formulation, operating on paths instead of flows. Let
$\mathcal{P}_j$ be the set of paths starting at $s_j$ and ending at
$t_J$.
Then we can define $\mathcal{P}$ to be the union of $\mathcal{P}_j$
for all $j$, that is, $\mathcal{P}$ is the set of all paths from $s_j$
to $t_j$ for any $j$. Let $\mathcal{P}_e$ be the set of paths in
$\mathcal{P}$ such that edge $e$ is in the path. Then our LP
formulation assigns a variable $x(p)$ for each path $p\in \mathcal{P}$
and has the following description:
\begin{align*}
\text{max     } \lambda \\
\text{s.t. }\sum_{p\in \mathcal{P}_e}x(p) \leq c(e) \;\;\forall\;
e\in E \\
\sum_{p\in \mathcal{P}_j} x(p)\geq \lambda\cdot d(j) \;\;\;\forall \;1\leq j\leq k \\
x\geq 0,\; \lambda\geq 0.
\end{align*}
In this case, $x(p)$ can be defined as the amount of flow we send
along path $p$. Then the first set of constraints ensures we don't
send flow across an edge that exceeds the edge's capacity. The second
constraint then maintains that the total flow sent from $s_j$ to $t_j$
is greater than $\lambda$ times the demand $d(j)$, ensuring that we
maximize the minimal ratio of flow to demand over all commodities. Both formulations solve an equivalent problem; however
it is clear that both formulations are exponential in the size of the graph. For this
reason many fully polynomial approximation schemes have been
developed. 
The first fully polynomial approximation schemes (FPAS) for solving
multi-commodity flow problems and their variants arose in the early
90's with Leighton et. al \cite{leighton}.
Typically, variants of multi-commodity flow problems have often been
solved with similar techniques. That is, the tricks that tend to work
well for solving one variant of a multi-commodity flow problem can
easily be extended to other multi-commody flow variants. For this
reason, in discussing the background of maximum concurrent flow (MCF),
we will describe the background of min-cost multi-commodity flow
(MCMCF) which has typically been the problem on which most of the
following techniques were first developed. Keep in mind that FPAS'
for MCMCF are easily extensible to MCF, often using the same tricks,
both in theory and to speed up implmentation in
practice.
Theoretically, these algorithms run faster than
interior-point methods for solving LP's, but it was several years
after the development of the theoretical development of
the first FPAS's that an efficient implementation was developed,
attaining a speed two-to-three orders of magnitude faster than
state-of-the-art linear program solvers \cite{goldberg}.
The main idea of how
these early FPAS' work is a rerouting method, generalizing on
fractional packing techniques \cite{karger}.
Initially, the
algorithm finds an initial flow satisfying the demands, but possibly
violating the capacities. Then the algorithm repeatedly
picks a commodity via round-robin fashion and reroutes flow using a
single-commodity minimum-cost flow in the auxiliary graph until the flow is feasible. The costs
on the edges of the auxiliary graph are initialized to a small value,
but are scaled for every unit of flow rerouted through them, ultimately
making the cost of an edge exponential in the amount of flow sent
through it. The 'goodness' of the reroutings are stored in a potential function, which
is guaranteed to generate a $1+\omega$ solution in
$\tilde{O}(\omega^{-3}kmn)$ time for the minimum cost multi-commodity flow
problem \cite{karger}. 
Since then, these bounds have since been increased to
$\tilde{O}(\omega^{-2}m^2)$ in 2000 \cite{grig}. 
Most recently, Jonathon Kelner of MIT proposed a method to find an $\omega$ approximate concurrent multicommodity flow problem
in  $O(m^{1+o(1)}\omega^{-2}k^2)$ time
using a combination of a
non-Euclidean generalization of gradient descent, flow sparsifiers,
and an $O(m^{o(1)})$-competitive oblivious routing scheme \cite{almostLinear}. 
